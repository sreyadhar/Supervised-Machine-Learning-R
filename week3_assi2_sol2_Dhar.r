# # -*- coding: utf-8 -*-
# """Week3 Assi2 Sol2.ipynb
# 
# Automatically generated by Colaboratory.
# 
# Original file is located at
#     https://colab.research.google.com/drive/1Ah3MiPXAWjaJ7nESHYT9xPalLLC2LNn-
# """

###########################################################################
## Week-4, Homework-2, Sol-2
## Sreya Dhar 
## Created: Sept 20, 2020
## Edited: Sept 27, 2020
###########################################################################

## installing all the libaries in R kernel

# install.packages("Hmisc")
# install.packages("funModeling")
# install.packages("PerformanceAnalytics")
# install.packages("corrplot")
# install.packages("hrbrthemes")
# install.packages("plotly")
# install.packages("caret")

## importing the libraries in R kernel

library(Hmisc)
library(ggplot2)
library(dplyr)
library(funModeling) 
library(tidyverse)
library(tidyr)
library(PerformanceAnalytics)
library(corrplot)
library(repr)
library(ggplot2)
library(reshape2)
library(gplots)
library(plotly)
library(caret)
library(pROC)
library(class)
library(ROCR)

rm(list = ls()) ## clearing working environment


# Set working directory to where data file is located
setwd("C:/File E/EAS 506 Statistical Mining I/Week 3/Assignment-2")

# Uploading Train file 
train <- as.data.frame(read.table(gzfile("zip.train.gz")))

# filter the data for training set in knn
train_y_knn <- filter(train, train['V1'] == 2 | train['V1'] == 3)
dim(train_y_knn)
train_x <- train_y_knn[, -1]
train_2 <- filter(train, train['V1'] == 2) 
train_3 <- filter(train, train['V1'] == 3) 
dim(train_2)
train_y <- train_y_knn[, 1] == 2
train_y_new <- ifelse(train_y_knn[, 1] == 2, 1, 0)

# dim(as.data.frame(train_y_knn['V1'] == 2))
# dim(as.data.frame(train_y_knn['V1'] == 3))

# Uploading Test file 
test <- as.data.frame(read.table(gzfile("zip.test.gz")))

# filter the data for test set in knn
test_y_knn <- filter(test, test['V1'] == 2 | test['V1'] == 3)
dim(test_y_knn)
test_x <- test_y_knn[, -1]
test_y <- test_y_knn[, 1] == 3
test_y_new <- ifelse(test_y_knn[, 1] == 2, 1, 0)

################################## Linear Regression  #################################

## min-max scaling on boston dataset prior to regression
max <- apply(train_x , 2 , max)
min <- apply(train_x, 2 , min)
train_s <- as.data.frame(scale(train_x, center = min, scale = max - min))

max <- apply(test_x , 2 , max)
min <- apply(test_x, 2 , min)
test_s <- as.data.frame(scale(test_x, center = min, scale = max - min))


df_lm <- cbind(train_y_new, train_s)

model_1 <- lm(train_y_new ~ ., data = df_lm)
summary(model_1)
par(mfrow=c(1,2))
options(repr.plot.width=6, repr.plot.height=3, repr.plot.res = 180)
plot(model_1) ## plot summary of the model

## predict the model on train set
fitted_model_tr <- predict(model_1, train_s, type='response')
fitted_results_tr <- ifelse(fitted_model_tr > 0.5,1,0)
error_tr <- mean(fitted_results_tr != train_y_new) ## error on train set
print(1-error_tr) ## Accuracy in train set
error_tr # TRAINING ERROR

1-error_tr # train accuracy

## predict the model on test set
fitted_model_1 <- predict(model_1, test_s, type='response')
fitted_results <- ifelse(fitted_model_1 > 0.5,1,0)
error <- mean(fitted_results != test_y_new) ## error on test set
print('Error of test set from linear regression')
error # test error

## creating confusion matrix
cfmat <- tibble("target" = test_y_new,
                     "prediction" = fitted_results)
cfm_tab <-table(cfmat)
cfm_tab # test confu. matrix

cfmat_tr <- tibble("target" = train_y_new,
                     "prediction" = fitted_results_tr)
cfm_tab_tr <-table(cfmat_tr)
cfm_tab_tr # train confu. matrix

## accuracy on test set
accu_lm <- 1-error

## ROC AUC plot
options(repr.plot.width=3, repr.plot.height=3, repr.plot.res = 180)
pred_1 <- prediction(fitted_model_1, test_y_new)
perform <- performance(pred_1, measure = "tpr", x.measure = "fpr")

plot(perform) ## plot ROC

roc_cur <- roc(test_y_new, fitted_model_1) ## AUC ROC
auc(roc_cur)

auc_1 <- performance(pred_1, measure = "auc")
auc_lm <- auc_1@y.values[[1]]
auc_lm ## accuracy from linear reg on test set

dim(df_lm['train_y_new'])

dim(df_lm[,2:257])

dim(test_s)

cl = df_lm[,1, drop = TRUE]

############ Knn prediction ########################

accuracy = function(actual, predicted) { ## defining accuracy function 
  mean(actual == predicted)}

error = function(actual, predicted) { ## defining error function 
  mean(actual != predicted)}

# set.seed(100)
iter_k = c(1,3,5,7,9,11,13,15) ## giving k-values
accu_k_te = rep(x = 0, times = length(iter_k))
accu_k_tr = rep(x = 0, times = length(iter_k))

error_k_te = rep(x = 0, times = length(iter_k))
error_k_tr = rep(x = 0, times = length(iter_k))

for(i in seq_along(iter_k)) {
  pred_k_te = knn( train = train_s, 
              test = test_s[,-257], 
              cl = train_y_new, 
              k = iter_k[i])
  accu_k_te[i] = accuracy(test_y_new, pred_k_te) ## accuracy from knn on test set
  error_k_te[i] = error(test_y_new, pred_k_te) ## error from knn on test set
  
} ## error from knn

error_k_tr

for(i in seq_along(iter_k)) {
  pred_k_tr = knn( train = train_s, 
                test = train_s, 
                cl = train_y_new, 
                k = iter_k[i])
  accu_k_tr[i] = accuracy(pred_k_tr,train_y_new) ## accuracy from knn on train set
  error_k_tr[i] = error(train_y_new, pred_k_tr) ## error from knn on train set
}

## converting dataset into matrix

train_y_dat <- data.frame(train_y_new)
test_y_dat <- data.frame(test_y_new)
pred_k_tr_dat <- data.frame(pred_k_tr)
pred_k_te_dat <- data.frame(pred_k_te)

# train_y_dat

dim(pred_k_tr_dat)

## error from knn

error_tr <- mean(train_y_new != pred_k_tr)
error_te <- mean(test_y_new != pred_k_te)

print(paste('Accuracy of test set from linear regression',1-error_tr))
print(paste('Accuracy of test set from linear regression',1-error_te))

c(error_te, error_tr)

accu_k_te

accu_k_tr

####################### Comparing classification accuracy in knn and lm model #########################
options(repr.plot.width=8, repr.plot.height=4, repr.plot.res = 180)
par(mfrow=c(1,2))

# plot accuracy vs choice of k on Training set
plot(iter_k, accu_k_tr*100, type = "b",col = "blue", cex = 1, pch = 20, lwd = 2, 
     xlab = "k, number of neighbors", ylim= c(95.5,100),
     ylab = "classification accuracy, %", main = "Accuracy of Training set")

abline(v = which.max(accu_k_tr),y = max(accu_k_tr)*100, type = "l", col = "red", lwd = 2)
abline(x = which.max(accu_k_tr),h = max(accu_k_tr)*100, type = "l", col = "black", lty = 2)
abline(a=100-0.6, b = 0, type = "l", col = "green", lty = 2, lwd = 3)

# plot accuracy vs choice of k on Test set
plot(iter_k,accu_k_te*100, type = "b", col = "blue", cex = 1, pch = 20, lwd = 2,
     ylim= c(95.5,100),
     xlab = "k, number of neighbors", ylab = "classification accuracy, %",
     main = "Accuracy of Test set")

abline(v = which.max(accu_k_te),y = max(accu_k_te)*100, type = "l", col = "red", lwd = 2)
abline(x = which.max(accu_k_te),h = max(accu_k_te)*100, type = "l", col = "black", lty = 2)
abline(a=100-4.12, b = 0, type = "l", col = "green", lty = 2, lwd = 3)

legend(100, "Regression Accuracy", lty= 2, lwd=3,col= "green")


######################### Comparing classification errors in knn and lm model #######################
options(repr.plot.width=8, repr.plot.height=4, repr.plot.res = 180)
par(mfrow=c(1,2))

# plot accuracy vs choice of k on Training set
plot(iter_k, error_k_tr*100, type = "b",col = "blue", cex = 1, pch = 20, lwd = 2, 
     xlab = "k, number of neighbors", ylim=c(0,5),
     ylab = "classification error, %", main = "classification error of Training set")

abline(v = which.min(error_k_tr),y = min(error_k_tr)*100, type = "l", col = "red", lwd = 2)
abline(x = which.min(error_k_tr),h = min(error_k_tr)*100, type = "l", col = "black", lty = 2)
abline(a=0.6, b = 0, type = "l", col = "green", lty = 2, lwd = 3)

legend(5, "Regression Error", lty= 2, lwd=3,col= "green")

# plot accuracy vs choice of k on Test set
plot(iter_k,error_k_te*100, type = "b", col = "blue", cex = 1, pch = 20, lwd = 2,
     ylim=c(0,5),
     xlab = "k, number of neighbors", ylab = "classification error, %",
     main = "classification error of Test set")

abline(v = which.min(error_k_te),y = min(error_k_te)*100, type = "l", col = "red", lwd = 2)
abline(x = which.min(error_k_te),h = min(error_k_te)*100, type = "l", col = "black", lty = 2)
abline(a=4.12, b = 0, type = "l", col = "green", lty = 2, lwd = 3)

## end ##