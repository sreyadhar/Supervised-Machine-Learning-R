# # -*- coding: utf-8 -*-
# """Week12 Assi6 Sol1.ipynb
# 
# Automatically generated by Colaboratory.
# 
# Original file is located at
#     https://colab.research.google.com/drive/1BQQr3Sr0RTmqE_pa-jB5QKD6VN15PBgZ
# """
# ###########################################################################
## Week-12, Homework-6, Sol-1
## Sreya Dhar 
## Created: Nov 24, 2020
## Edited: Dec 03, 2020
###########################################################################

# ## installing all the libaries in R kernel
# 
# install.packages("corrplot")
# install.packages("forecast")
# install.packages("zoo")
# install.packages("rsample")
# install.packages("leaps")
# install.packages("car")
# install.packages("caret")
# install.packages("ROCR")
# install.packages("PerformanceAnalytics")
# install.packages("funModeling")
# install.packages("hrbrthemes")
# install.packages("ggthemes")
# install.packages("GGally")
# install.packages("glmnet")
# install.packages("ISLR")
# install.packages("kableExtra")
# install.packages("broom")
# install.packages("knitr")
# install.packages("psych")
# install.packages("aod")
# install.packages("epiDisplay")
# install.packages("e1071")
# install.packages("class")
# install.packages('tree')
# install.packages('rpart')
# install.packages('rattle')
# install.packages("partykit")
# install.packages("randomForest")
# install.packages("party")
# install.packages("kernlab")
# install.packages("gbm")
# install.packages("plotmo")
# install.packages("pdp")
# """# New Section"""

## importing the libraries in R kernel

library(ggplot2)
library(dplyr)
library(tidyverse)
library(tidyr)
library(corrplot)
library(repr)
library(reshape2)
library(forecast)
library(zoo)
library(rsample)
library(gplots)
library(ROCR)
library(class)
library(readr)
library(leaps)
library(car)
library(PerformanceAnalytics)
library(funModeling)
library(caret)
library(MASS)
library(Hmisc)
library(hrbrthemes)
library(GGally)
library(glmnet)
library(pROC)
library(ISLR)
library(psych)
library(aod)
library(epiDisplay)
library(e1071)
library(ggthemes)
library(kableExtra)
library(broom)
library(knitr)
library(rpart)
library(rattle)
library(partykit)
library(randomForest)
library(tree)
library(party)
library(kernlab)
library(gbm)
library(plotmo)
library(tree)
library(pdp)


## uploading the data
data(OJ)
head(OJ)

head(OJ)


glimpse(OJ)

names(OJ)

status(OJ)

profiling_num(OJ)

describe(OJ)

summary(OJ)

options(repr.plot.width=8, repr.plot.height=8, repr.plot.res = 230)

pairs.panels(OJ[,2:18], main = "Pairs plot on OJ dataset, unclassed on Purchase", pch = 21, bg = c("blue", "green")[unclass(OJ$Purchase)], hist.col="red")

options(repr.plot.width=6, repr.plot.height=6, repr.plot.res = 200)
plot_num(OJ)

# OJ <- pima %>% mutate_if(is.character, as.factor)
OJ_n <- OJ %>% mutate_if(is.factor, as.numeric)

head(OJ_n)

# heatmap matrix 
options(repr.plot.width=5, repr.plot.height=5, repr.plot.res = 230)
data_h <- as.data.frame(scale(OJ_n,center=TRUE,scale=TRUE))
heatmap.2(as.matrix(OJ_n), scale = "none", col = bluered(100), trace = "none", density.info = "none")

options(repr.plot.width=6, repr.plot.height=6, repr.plot.res = 200)
L <- cor(OJ_n)
corrplot(L, method = "circle",  type = "lower")

########################################################################
##################### Classification Tree with rpart ###################
########################################################################
# Normalizing the predictor variable 

# ## min-max scaling on vehicle dataset predictors prior to classification
normalized<-function(y) {
  
  x<-y[!is.na(y)]
  
  x<-(x - min(x)) / (max(x) - min(x))
  
  y[!is.na(y)]<-x
  
  return(y)
}

OJ[,2:18]<-apply(OJ_n[,c(2:18)],2,normalized)
head(OJ)

## splitting the dataset into train and test sets
set.seed(1234) ## seeding the sampling
data_split <- initial_split(OJ, prop = 0.75) ## spliting the data by library 'rsample'
data_train <- training(data_split)
data_test  <- testing(data_split)

###################################################################
###################### Bagging ####################################
###################################################################

bag <- randomForest(factor(Purchase) ~ ., mtry = 17, ntrees=500, importance = TRUE, data_train) ## suggested mtry=sqrt(p) 
bag_pred_tr <- predict(bag, data_train[,-1], type='class')  
bag_pred_te <- predict(bag, data_test[,-1], type='class')
bag_tab_tr <- table(Original=data_train$Purchase, Prediction=bag_pred_tr)
bag_tab_te <- table(Original=data_test$Purchase, Prediction=bag_pred_te)

confusionMatrix(bag_tab_tr)

confusionMatrix(bag_tab_te)

importance(bag, type = 1)
varImpPlot(bag, type = 1)

##############################################################
#################### Random Forest ###########################
##############################################################
rf <- randomForest(factor(Purchase) ~., data=data_train, importance=TRUE, do.trace=100, ntree=500, mtry = 3)
print(rf)

rf$err.rate[500]

options(repr.plot.width=10, repr.plot.height=7, repr.plot.res = 200)
varImpPlot(rf, main="Variable Importance Accuracy and Gini coeff. from Random Forest")

importance(rf)

## Prediction on train set
rf_pred_tr <- predict(rf, data_train, type = "response")
rf_tab <- confusionMatrix(table(data_train$Purchase, rf_pred_tr))
rf_tab

## Prediction on test set
rf_predict <- predict(rf, data_test,type = "response")
rf_tab <- confusionMatrix(table(data_test$Purchase, rf_predict))
rf_tab

options(repr.plot.width=8, repr.plot.height=8, repr.plot.res = 230)
plotres(rf)

rf_tree <- getTree(rf, k=2) # show the second tree
# print(rf_tree)

treesize(rf) # size of trees of the ensemble

mean(treesize(rf))

options(repr.plot.width=4, repr.plot.height=4, repr.plot.res = 200)
hist(treesize (rf), col = "red")

######################################### Iteration on mtry for RF #########################################

rf.c <- list()
oob.err <- list()
yhat.rf <-list()
misclass_rf<-list()
for ( i in 1:17 ) {
  set.seed(4444)
  rf.c<-randomForest(Purchase ~ ., data = data_train, mtry = i, importance = TRUE, ntree = 500)
  oob.err[i] = rf.c$err.rate[500] #Error of all Trees fitted
  yhat.rf<-predict(rf.c, newdata = data_test[,-1])
  misclass_rf[i]<- mean(yhat.rf != data_test$Purchase)
}

options(repr.plot.width=6, repr.plot.height=4, repr.plot.res = 200)
matplot(1:17, misclass_rf, xlab = 'No. of Variables (mtry)', ylab = 'Misclassification error', main = "Subset size Vs. Misclassification error")
lines(1:17, misclass_rf, type = "o")

options(repr.plot.width=7, repr.plot.height=6, repr.plot.res = 200)
matplot(1:17 , cbind(oob.err, misclass_rf), pch=19 , col=c("red","blue"), type=c("o","o"), ylab="Misclassification Error rate", xlab="Number of Predictors Considered at each Split, mtry", lty=1, lwd=2)
legend("topright", legend=c("Out of Bag Error","Test Error"), pch=19, col=c("red","blue"))

misclass_rf ## min for mtry=4,7 on test set

################ Tuning on RF model ###############

library("e1071") # to 'tune' the rf model

tuned_rf <- tune(randomForest, train.x = Purchase ~ ., data = data_train, validation.x = data_test, mtry=4, ntree=500)

best_rf <- tuned_rf$best.model
best_rf_pred <- predict(best_rf, data_test, type='response')
tab_best_rf <- table(Reference=data_test$Purchase, Prediction=best_rf_pred)
confusionMatrix(tab_best_rf)

tuned_rf

best_rf

options(repr.plot.width=10, repr.plot.height=5, repr.plot.res = 200)
par(mfrow=c(1,2))
plot(rf)
plot(best_rf)

# computing overall error:
err_rf <- 1 - sum(diag(as.matrix(tab_best_rf))) / sum(tab_best_rf)
err_rf



options(repr.plot.width=8, repr.plot.height=8, repr.plot.res = 230)
plotmo(rf,  pmethod="partdep", all1=TRUE )

data_train_n <- data_train %>% mutate_if(is.factor, as.numeric)-1
data_test_n <- data_test %>% mutate_if(is.factor, as.numeric)-1

###############################################
# Boosting ##
###############################################
mod_boost = gbm(Purchase ~.,
              data = data_train_n,
              distribution = "adaboost",
              cv.folds = 10,
              shrinkage = .1,
              n.minobsinnode = 10,
              n.trees = 200)

print(mod_boost)

options(repr.plot.width=8, repr.plot.height=8, repr.plot.res = 230)
plotres(mod_boost)

mod_boost1 = gbm(Purchase ~.,
              data = data_train,
              distribution = "multinomial",
              cv.folds = 10,
              shrinkage = .1,
              n.minobsinnode = 10,
              n.trees = 200)

print(mod_boost1)

### prediction on train set from boosting ###
pred_boost_tr = predict.gbm(object = mod_boost1,
                            newdata = data_train,
                            n.trees = 200,
                            type = "response")

labels_tr = colnames(pred_boost_tr)[apply(pred_boost_tr, 1, which.max)]
result_tr = data.frame(data_train$Purchase, labels_tr)
confusionMatrix(data_train$Purchase, as.factor(labels_tr))

### prediction on test set from boosting ###
pred_boost_te = predict.gbm(object = mod_boost1,
                   newdata = data_test,
                   n.trees = 200,
                   type = "response")


labels = colnames(pred_boost_te)[apply(pred_boost_te, 1, which.max)]
result = data.frame(data_test$Purchase, labels)
# print(result)

confusionMatrix(data_test$Purchase, as.factor(labels))

#### Shrinkage factor iteration for boosting ###
shrink <- c(.1, .4, .6, .8)
max_iter <- 5000
store_error <- c()
for (i in 1:length(shrink)){
	boost.fit <- gbm(Purchase~., data = data_train_n, n.trees = max_iter, shrinkage = shrink[i], interaction.depth = 3, distribution = "adaboost")
	temp <- c()
	for (j in 1:max_iter){
		y_hat <- predict(boost.fit, newdat = data_test_n, n.trees = j, type = "response")
		misclass_boost <- mean(y_hat != data_test_n$Purchase)
		temp <- c(temp, misclass_boost)
	}
	store_error <- cbind(store_error, temp) # max_iter x length(shrink)
}

colnames(store_error) <- paste("shrinkage", shrink, sep = ":")

options(repr.plot.width=7, repr.plot.height=7, repr.plot.res = 200)
plot(store_error[,1], type = "l", main = "Error Profiles", ylab = "error", xlab = "boosting iterations", ylim=c(0.955,1))
lines(store_error[,2], col = "red")
lines(store_error[,3], col = "blue")
lines(store_error[,4], col = "green")
legend("bottomleft", legend=c("shrinkage = 0.1","shrinkage = 0.4", "shrinkage = 0.6", "shrinkage = 0.8"), pch=19, col=c('black',"red","blue", "green"))

options(repr.plot.width=12, repr.plot.height=10, repr.plot.res = 230)
plotmo(mod_boost,  pmethod="partdep", all1=TRUE)

###################################################################
############ Knn prediction on the dataset ########################
###################################################################

accuracy = function(actual, predicted) { ## defining accuracy function 
  mean(actual == predicted)}

error = function(actual, predicted) { ## defining error function 
  mean(actual != predicted)}

iter_k = c(1,3,5,7,9,13,15) ## giving k-values
accu_pca_te = rep(x = 0, times = length(iter_k))
accu_pca_tr = rep(x = 0, times = length(iter_k))

error_pca_te = rep(x = 0, times = length(iter_k))
error_pca_tr = rep(x = 0, times = length(iter_k))

for(i in seq_along(iter_k)) {
  pred_pca_tr = knn( train = data_train[,2:18], 
                     test = data_train[,2:18], 
                     cl = data_train$Purchase, 
                     k = iter_k[i])
  accu_pca_tr[i] = accuracy(pred_pca_tr,data_train$Purchase) ## accuracy from knn on train set
  error_pca_tr[i] = error( pred_pca_tr, data_train$Purchase) ## error from knn on train set
} ## error from knn train set


for(i in seq_along(iter_k)) {
  pred_pca_te = knn( train = data_train[,2:18], 
                     test = data_test[,2:18], 
                     cl = data_train$Purchase, 
                     k = iter_k[i])
  accu_pca_te[i] = accuracy(pred_pca_te, data_test$Purchase) ## accuracy from knn on test set
  error_pca_te[i] = error(pred_pca_te, data_test$Purchase) ## error from knn on test set
  
} ## error from knn test set

error_pca_train <- mean(data_train$Purchase != pred_pca_tr)
error_pca_test  <- mean(data_test$Purchase != pred_pca_te)

print(paste('Accuracy of train set from KNN',(1-error_pca_train)*100,'%'))
print(paste('Accuracy of test set from KNN',(1-error_pca_test)*100,'%'))

c(error_pca_te, error_pca_tr)

####################### Comparing classification accuracy and errror in knn from PCA components  #########################
options(repr.plot.width=8, repr.plot.height=8, repr.plot.res = 200)
par(mfrow=c(2,2))

# plot accuracy vs choice of k on Training set
plot(iter_k, accu_pca_tr*100, type = "b",col = "blue", cex = 1, pch = 20, lwd = 2,
     xlab = "k, number of neighbors", ylim= c(70,100),
     ylab = "classification accuracy, %", main = "Accuracy of Training set")

abline(v = which.max(accu_pca_tr),y = max(accu_pca_tr)*100, type = "l", col = "red", lwd = 2, lty = 2)
abline(x = which.max(accu_pca_tr),h = max(accu_pca_tr)*100, type = "l", col = "black", lty = 2)


# plot accuracy vs choice of k on Test set
plot(iter_k, accu_pca_te*100, type = "b", col = "blue", cex = 1, pch = 20, lwd = 2,
     ylim= c(70,100),
     xlab = "k, number of neighbors", ylab = "classification accuracy, %",
     main = "Accuracy of Test set")

abline(v = 9,y = max(accu_pca_te)*100, type = "l", col = "red", lwd = 2, lty = 2)
abline(x = which.max(accu_pca_te),h = max(accu_pca_te)*100, type = "l", col = "black", lty = 2)

# plot accuracy vs choice of k on Training set
plot(iter_k, error_pca_tr*100, type = "b",col = "blue", cex = 1, pch = 20, lwd = 2, 
     xlab = "k, number of neighbors", ylim=c(0,30),
     ylab = "classification error, %", main = "classification error of Training set")

abline(v = which.min(error_pca_tr),y = min(error_pca_tr)*100, type = "l", col = "red", lwd = 2, lty = 2)
abline(x = which.min(error_pca_tr),h = min(error_pca_tr)*100, type = "l", col = "black", lty = 2)

# # plot accuracy vs choice of k on Test set
plot(iter_k, error_pca_te*100, type = "b", col = "blue", cex = 1, pch = 20, lwd = 2,
     ylim=c(0,30),
     xlab = "k, number of neighbors", ylab = "classification error, %",
     main = "classification error of Test set")

abline(v = 9,y = min(error_pca_te)*100, type = "l", col = "red", lwd = 2, lty = 2)
abline(x = which.min(error_pca_te),h = min(error_pca_te)*100, type = "l", col = "black", lty = 2)

### end ###